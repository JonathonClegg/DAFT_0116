{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario\n",
    "\n",
    "You are working as an analyst with this internet service provider. You are provided with this historical data about your company's customers and their churn trends. Your task is to build a machine learning model that will help the company identify customers that are more likely to default/churn and thus prevent losses from such customers.\n",
    "\n",
    "Instructions\n",
    "\n",
    "In this lab, we will first take a look at the degree of imbalance in the data and correct it using the techniques we learned on the class. Here is the list of steps to be followed (building a simple model without balancing the data):\n",
    "\n",
    "Round 1\n",
    "\n",
    " Import the required libraries and modules that you would need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read that data into Python and call the dataframe churnData."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "churnData = pd.read_csv(\"/Users/jon/Documents/IRONHACK/DAFT_0116/module_3/LAB Imbalanced Classification Task/DATA_Customer-Churn.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7043, 16)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churnData.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the datatypes of all the columns in the data.You would see that the column TotalCharges is object type. Convert this column into numeric type using pd.to_numeric function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender               object\n",
       "SeniorCitizen         int64\n",
       "Partner              object\n",
       "Dependents           object\n",
       "tenure                int64\n",
       "PhoneService         object\n",
       "OnlineSecurity       object\n",
       "OnlineBackup         object\n",
       "DeviceProtection     object\n",
       "TechSupport          object\n",
       "StreamingTV          object\n",
       "StreamingMovies      object\n",
       "Contract             object\n",
       "MonthlyCharges      float64\n",
       "TotalCharges         object\n",
       "Churn                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churnData.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "churnData[\"TotalCharges\"] = pd.to_numeric(churnData[\"TotalCharges\"], errors='coerce')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for null values in the dataframe. Replace the null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender               0\n",
       "SeniorCitizen        0\n",
       "Partner              0\n",
       "Dependents           0\n",
       "tenure               0\n",
       "PhoneService         0\n",
       "OnlineSecurity       0\n",
       "OnlineBackup         0\n",
       "DeviceProtection     0\n",
       "TechSupport          0\n",
       "StreamingTV          0\n",
       "StreamingMovies      0\n",
       "Contract             0\n",
       "MonthlyCharges       0\n",
       "TotalCharges        11\n",
       "Churn                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churnData.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender              0\n",
       "SeniorCitizen       0\n",
       "Partner             0\n",
       "Dependents          0\n",
       "tenure              0\n",
       "PhoneService        0\n",
       "OnlineSecurity      0\n",
       "OnlineBackup        0\n",
       "DeviceProtection    0\n",
       "TechSupport         0\n",
       "StreamingTV         0\n",
       "StreamingMovies     0\n",
       "Contract            0\n",
       "MonthlyCharges      0\n",
       "TotalCharges        0\n",
       "Churn               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churnData.fillna(churnData.median(), inplace=True)\n",
    "churnData.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following features: tenure, SeniorCitizen, MonthlyCharges and TotalCharges:\n",
    "\n",
    "Split the data into a training set and a test set.\n",
    "\n",
    "Scale the features either by using MinMaxScaler or a standard scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "churnData.loc[(churnData['Churn']==\"No\"), 'Churn'] = '0'\n",
    "churnData.loc[(churnData['Churn']==\"Yes\"), 'Churn'] = '1'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = churnData[[\"tenure\", \"SeniorCitizen\", \"MonthlyCharges\", \"TotalCharges\"]]\n",
    "y = churnData[\"Churn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# transform data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test) #No need to use fit since we should normalize the training set and then use the same normalization steps on the test set\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROUND 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) Fit a logistic Regression model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression() \n",
    "\n",
    "#trans=PowerTransformer() #Optional transformation\n",
    "#trans.fit(X_train_scaled)\n",
    "#X_train_mod = trans.transform(X_train_scaled)\n",
    "#X_test_mod  = trans.transform(X_test_scaled)\n",
    "log_model.fit(X_train_scaled, y_train)\n",
    "log_y_pred_test = log_model.predict(X_test_scaled) # predict test\n",
    "log_y_pred_train=log_model.predict(X_train_scaled) # predict train (for sanity checks)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a Knn Classifier (NOT KnnRegressor please!)model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=2,weights='uniform') # declare we're using knn classification model\n",
    "knn_model.fit(X_train, y_train) # train model\n",
    "knn_y_pred = knn_model.predict(X_test) # predict test\n",
    "knn_y_pred_train=knn_model.predict(X_train) # predict train (for sanity checks)\n",
    "#model.predict_proba(inputdata)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a Decision Tree Classifier on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier(max_depth=3) #Comes from sklearn.tree\n",
    "\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train_dt = dt_model.predict(X_train)\n",
    "y_pred_test_dt = dt_model.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the accuracy, precision, recall for the previous models on both the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error_metric</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.788782</td>\n",
       "      <td>0.801987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.645975</td>\n",
       "      <td>0.692607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.446680</td>\n",
       "      <td>0.470899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Error_metric     Train      Test\n",
       "0     Accuracy  0.788782  0.801987\n",
       "1    Precision  0.645975  0.692607\n",
       "2       Recall  0.446680  0.470899"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error_metric</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.865637</td>\n",
       "      <td>0.765791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.634831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.497653</td>\n",
       "      <td>0.298942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Error_metric     Train      Test\n",
       "0     Accuracy  0.865637  0.765791\n",
       "1    Precision  0.989333  0.634831\n",
       "2       Recall  0.497653  0.298942"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error_metric</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.784523</td>\n",
       "      <td>0.784244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.647184</td>\n",
       "      <td>0.672897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.408451</td>\n",
       "      <td>0.380952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Error_metric     Train      Test\n",
       "0     Accuracy  0.784523  0.784244\n",
       "1    Precision  0.647184  0.672897\n",
       "2       Recall  0.408451  0.380952"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "performance_log = pd.DataFrame({'Error_metric': ['Accuracy','Precision','Recall'],\n",
    "                               'Train': [accuracy_score(y_train, log_y_pred_train),\n",
    "                                         precision_score(y_train, log_y_pred_train, pos_label='1'),\n",
    "                                         recall_score(y_train, log_y_pred_train, pos_label='1')],\n",
    "                               'Test': [accuracy_score(y_test, log_y_pred_test),\n",
    "                                        precision_score(y_test, log_y_pred_test, pos_label='1'),\n",
    "                                        recall_score(y_test, log_y_pred_test, pos_label='1')]})\n",
    "\n",
    "display(performance_log)\n",
    "\n",
    "performance_knn = pd.DataFrame({'Error_metric': ['Accuracy','Precision','Recall'],\n",
    "                               'Train': [accuracy_score(y_train, knn_y_pred_train),\n",
    "                                         precision_score(y_train, knn_y_pred_train, pos_label='1'),\n",
    "                                         recall_score(y_train, knn_y_pred_train, pos_label='1')],\n",
    "                               'Test': [accuracy_score(y_test, knn_y_pred),\n",
    "                                        precision_score(y_test, knn_y_pred, pos_label='1'),\n",
    "                                        recall_score(y_test, knn_y_pred, pos_label='1')]})\n",
    "\n",
    "display(performance_knn)\n",
    "\n",
    "performance_dt = pd.DataFrame({'Error_metric': ['Accuracy','Precision','Recall'],\n",
    "                               'Train': [accuracy_score(y_train, y_pred_train_dt),\n",
    "                                         precision_score(y_train, y_pred_train_dt, pos_label='1'),\n",
    "                                         recall_score(y_train, y_pred_train_dt, pos_label='1')],\n",
    "                               'Test': [accuracy_score(y_test, y_pred_test_dt),\n",
    "                                        precision_score(y_test, y_pred_test_dt, pos_label='1'),\n",
    "                                        recall_score(y_test, y_pred_test_dt, pos_label='1')]})\n",
    "\n",
    "display(performance_dt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a4fddbfe8d809e2d3e9162ef69ab0c6689347e519fade92586b6599260d81fd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
